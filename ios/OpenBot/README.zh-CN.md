# Robot iOS App - Beta Release

<p align="center">
  <a href="README.md">English</a> |
  <span>简体中文</span> |
  <a href="README.de-DE.md">Deutsch</a> |
  <a href="README.fr-FR.md">Français</a> |
  <a href="README.es-ES.md">Español</a>
</p>

## 免责声明

1. **安全性：** 请确保您在安全的环境中操作。请记住，您的手机可能会在碰撞中受损！在使用自动控制（例如跟随人或驾驶策略）时需要特别小心。请确保您始终连接了游戏控制器，并熟悉按键映射，以便随时停止车辆。使用风险自负！
2. **应用程序正在开发中：** 该应用程序正在开发中，可能会根据您的手机型号和操作系统版本出现崩溃或意外行为。请确保在没有连接车轮的情况下测试所有功能。使用风险自负！

## 应用程序界面

### 主菜单

应用程序启动时会显示一个菜单屏幕，展示所有可用的屏幕。点击右上角的蓝牙图标可以打开蓝牙连接屏幕。点击旁边的设置图标可以打开设置屏幕。点击其他图标，用户可以访问各种屏幕，其功能将在后续部分中解释。

<p align="left">
<img style="padding-right: 2%;" src="../../docs/images/ios_main_screen.jpg" alt="主菜单" width="25%"/>
<img style="padding-right: 2%;" src="../../docs/images/ios_bluetooth_screen.jpg" alt="蓝牙" width="25%"/>
<img style="padding-right: 2%;" src="../../docs/images/ios_settings_screen.jpg" alt="设置" width="25%"/>
</p>

#### 蓝牙连接

与允许通过USB电缆将智能手机连接到OpenBot低级控制板的Android应用程序不同，iOS应用程序仅依赖于蓝牙低功耗（BLE）无线连接。在iOS应用程序中打开蓝牙连接屏幕时（通过点击主屏幕或任何片段中的蓝牙标志），会显示所有兼容设备的列表。兼容性通过在[应用程序](https://github.com/3dwesupport/OpenBot/blob/090dcb28206195a7ee45a13b8ded968a8d365abe/ios/OpenBot/OpenBot/Utils/Constants.swift#L57)和[固件](https://github.com/3dwesupport/OpenBot/blob/090dcb28206195a7ee45a13b8ded968a8d365abe/firmware/openbot_nano/openbot_nano.ino#L115)级别分配给OpenBot车辆的一系列特定UUID来强制执行。您必须确保这些UUID匹配。将iOS设备与OpenBot车辆配对只需从列表中选择该车辆并按下“连接”按钮。连接的默认波特率设置为115200，可以在应用程序和固件级别更改。

<p align="left">
<img src="../../docs/images/ios_ble.gif" alt="BLE连接" width="25%" />
</p>

### 自由漫游

自由漫游提供简单的机器人控制，并实时更新电池、电量和与表面的距离信息。它还提供与控制器、驾驶模式和速度相关的控制。

<p align="left">
<img src="../../docs/images/ios_free_roam_screen.jpg" alt="自由漫游" width="50%" />
</p>

- **电池：** 电池图标显示连接机器人的实时电池电量。

- **驾驶模式：** 视图上显示三种驾驶模式：

    - D -> 驾驶，当机器人向前行驶时

    - N -> 空档，当机器人静止时

    - R -> 倒车，当机器人向后移动时

- **速度：** 速度计显示机器人的实时速度。

- **声纳：** 声纳视图显示机器人与迎面物体的距离（以厘米为单位）。

- **蓝牙：** 显示与微控制器的蓝牙连接状态。点击图标，用户还可以跳转到蓝牙屏幕查看/修改连接。

#### 控制

第一个按钮用于选择**控制模式**。有两种不同的控制模式：

- **游戏手柄：** 应用程序接收来自连接的蓝牙控制器的控制。
- **手机（即将推出）：** 机器人可以通过安装了控制器应用程序的另一部智能手机或通过连接到同一网络的计算机上运行的Python脚本进行控制。

第二个按钮用于选择**驾驶模式**。使用游戏控制器（例如PS4）时，有三种不同的驾驶模式：

- **游戏：** 使用右肩和左肩触发器（R2，L2）进行前进和倒车油门，并使用任意一个摇杆进行转向。此模式模仿赛车视频游戏的控制模式。
- **摇杆：** 使用任意一个摇杆控制机器人。
- **双摇杆：** 使用左摇杆和右摇杆分别控制汽车的左侧和右侧。这是原始的差速转向。

第三个按钮用于选择**速度模式**。有三种不同的速度模式：

- **慢速：** 应用于电机的电压限制为输入电压的50%（约6V）。
- **正常：** 应用于电机的电压限制为输入电压的75%（约9V）。
- **快速：** 没有限制。全油门时将对电机应用全输入电压（约12V）。*这是运行神经网络的默认设置。*

以更高的速度运行会减少电机的使用寿命，但更有趣。发送到机器人的控制显示在右侧。使用游戏控制器时，可以通过按下右摇杆（R3）增加速度模式，通过按下左摇杆（L3）减少速度模式。

### 数据收集

用于收集数据集的简单UI。

<p align="left">

<img src="../../docs/images/ios_data_collection_screen.jpg" alt="数据收集" width="50%" />

</p>

- **预览分辨率：** 用于切换相机预览的分辨率。有3种设置：

    - ***高*** (1920x1080p)

    - ***中*** (1280x720p)

    - ***低*** (640x360)

- **模型分辨率：** 用于切换保存用于训练不同模型的图像分辨率。

- **记录收集的数据：** 数据收集过程可以从屏幕或远程控制，例如通过蓝牙控制器进行控制。使用蓝牙控制器时，您可以：

    - 按下**A按钮**以**开始**数据收集过程

    - 再次按下**A按钮**以**停止**数据收集并将收集的数据保存到.zip文件中

    - 或者按下**R1按钮**以**停止**数据收集**而不保存**收集的数据（例如由于意外碰撞环境）

    - 请记住使用控制器映射片段以确保您使用的是正确的按钮。

- **车辆状态：** **电池**字段显示微控制器通过分压器测量的电池电压。**速度（左，右）**字段报告（前）轮的左侧和右侧速度（以rpm为单位）。它由微控制器通过光学车轮速度传感器测量。**声纳**字段显示汽车前方的空闲空间（以厘米为单位）。它由微控制器通过超声波传感器测量。请注意，USB连接建立后几秒钟内您才会收到数值。

- **传感器：** 报告车辆传感器的测量值。目前，我们记录以下传感器的读数：相机、陀螺仪、加速度计、磁力计、环境光传感器和气压计。使用iOS API，我们能够获得以下传感器读数：RGB图像、角速度、线性加速度、重力、磁场强度、光强度、大气压力、纬度、经度、高度、方位和速度。除了手机传感器外，我们还记录通过串行链接传输的车身传感器读数（车轮里程计、障碍物距离和电池电压）。如果存在连接的控制器，我们还记录并时间戳控制信号。最后，我们集成了几种用于跟随人和自主导航的神经网络。

### 控制器映射

用于检查连接的蓝牙控制器的按钮和摇杆映射的简单UI。

<p align="left">
<img src="../../docs/images/ios_controller_mapping.jpg" alt="控制器映射" width="30%" />
</p>

### 机器人信息

用于获取机器人信息和测试基本功能的简单UI。固件中配置的**机器人类型**以文本和动画形式显示。**传感器**、**车轮里程计**和**LED**部分的复选标记显示连接的机器人支持哪些功能。**读数**部分提供最重要的传感器测量值。在**发送命令**部分，用户可以通过按下相应的按钮发送基本电机命令，并通过滑块控制前后LED。

<p align="left">
<img src="../../docs/images/ios_screen_robot_info.gif" alt="机器人信息" width="50%" />
</p>

### 自动驾驶

用于运行自动驾驶模型的简单UI。

<p align="left">

<img src="../../docs/images/ios_autopilot_screen.jpg" alt="自动驾驶" width="50%" />

</p>

### 物体跟踪

用于跟踪80种不同类别物体的简单UI。有关物体跟踪的不同AI模型和性能基准的简短描述可以在[模型管理](#model-management)中找到。

<p align="left">
<img src="../../docs/images/ios_object_tracking_screen.jpg" alt="物体跟踪" width="50%" />
</p>

### 模型管理

所有模型都经过量化以提高嵌入式设备上的性能。请注意，具有较大输入分辨率的模型可能尽管mAP较低，但对较小物体更好。

<p align="left">
<img src="../../docs/images/ios_screen_model_management.gif" alt="模型管理" width="25%" />
</p>

## 代码结构

[TensorFlow Lite 物体检测 iOS 示例](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/ios)被用作集成TFLite模型和获取相机视频流的起点。[tflite](OpenBot/tflite)文件夹包含[自动驾驶](OpenBot/tflite/Autopilot.swift)和[检测器](OpenBot/tflite/Detector.swift)网络的模型定义。

## 下一步（可选）

训练您自己的[驾驶策略](../../policy/README.md)